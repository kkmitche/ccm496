<DOCTYPE! html>
    <html>

    <head>
        <title>Who Is Responsible?</title>
        <link href="styles.css" rel="stylesheet" type="text/css" />
    </head>

    <body>
        <header>
            <h1>OUR TECHNOLOGICAL FUTURE</h1>
            <h2>AI, BIAS & THE THREAT TO DEMOCRACY</h2>
            <nav>
                <ul>
                    <li><a href="index.html">HOME</a></li>
                    <li><a href="resources.html">RESOURCES</a></li>
                </ul>
            </nav>
        </header>
        <div class="padlet-embed" id="responsiblePad" style="border:1px solid rgba(0,0,0,0.1);border-radius:2px;box-sizing:border-box;overflow:hidden;position:relative;width:100%;background:#F4F4F4">
            <p style="padding:0;margin:0"><iframe src="https://padlet.com/embed/1yft2knpul81nsry" scrolling="no" style="width:100%;height:500px;overflow:hidden"></iframe></p>
        </div>
        <div id="main">
            <div id="">
                <h1>Who Is Responsible?</h1>
                <!-- <h2>....</h2> -->
                <br/>
                <blockquote>"Google's position is that it is not responsible for its algorithm...If Google software engineers are not responsible for the design of their algorithms, then who is?" - Safiya Noble, author of Algorithms of Oppression
                </blockquote>
                <br/>
                <p>Silicon Valley is home to some of the smartest, brightest software engineers, and yet whenever something goes wrong within the algorithms they've built, they say it's too difficult for them to fix, or they deflect the responsibility onto
                    someone else. This is inexcusable for them to not be held accountable for the systems they create and the destruction they cause.
                </p>
                <br/>
                <p>The biggest argument these companies hide behind is the idea that it's not the algorithm that's the problem, but rather the users of the algorithm. Using this argument, it's not the algorithm's fault that inappropriate content or fake
                    news is displayed first in the search engine results, but rather the user's fault for searching a term, even when the terminology is completely unrelated. The missing piece here is the design of the algorithm and the lack of transparency
                    in how it works. Once again, the brightest of engineers have built these algorithms, but blame users for the problems they incur. This is a war waged on unequal playing ground.
                </p>
                <br/>
                <blockquote>"Silicon Valley designs its products with behavioral economics, which is to say with the economics of manipulation changing choice architectures, using that asymmetry, and they defend themselves to Congress and governments using regular,
                    neoliberal economics that humans are free, rational choosers, agents of their own design, making their own choices throughout the world. So, they're pretending they're in this equal contract relationship, while actually being in an
                    asymmetrical relationship.” - Tristan Harris, host of Your Undivided Attention podcast
                </blockquote>
                <br/>
                <p>We, as users, can't be held responsible for the problems within the digital infrastructure. As Harris points out, we are being manipulated beyond our comprehension so it's inconceivable that we can be at fault. However, we <i>are</i> responsible
                    for holding tech companies accountable for their actions and the algorithms they are building. We have to speak up and call them out, demanding transparency and accountability in order for us to see change. This is crucial for the
                    future of our democracy and our freedom.
                </p>
                <br/>
                <br/>
                <div class="conWorks">
                    <h2>CONSULTED WORKS</h2>
                    <ul>
                        <li><a href="https://www.netflix.com/search?q=coded%20bias&jbv=80117542" target="_blank">Amer, K. & Noujaim, J. (2019). <i>The Great Hack</i> [Film]. The Othrs Media Company.</a></li>
                        <li><a href="https://www.humanetech.com/podcast/3-with-great-power-comes-no-responsibility" target="_blank">Harris, T., & Raskin, A. (Hosts). (2019, June 25). With Great Power Comes...No Responsibility? (No. 3) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                        <li><a href="http://algorithmsofoppression.com/" target="_blank">Noble, S.U. (2018). <i>Algorithms of Oppression: How Search Engines Reinforce Racism</i>. New York University Press.</a></li>
                    </ul>
                    <br/>
                    <br/>
                </div>
            </div>

            <div class="recRes">
                <h3>RECOMMENDED RESOURCES</h3>
                <ul>
                    <li><a href="https://www.netflix.com/search?q=coded%20bias&jbv=80117542" target="_blank">Amer, K. & Noujaim, J. (2019). <i>The Great Hack</i> [Film]. The Othrs Media Company.</a></li>
                    <li><a href="https://www.humanetech.com/learn-more" target="_blank">Center for Humane Technology. (2021, Apr 5). Learn More [Website].</a></li>
                    <li><a href="https://www.humanetech.com/podcast/3-with-great-power-comes-no-responsibility" target="_blank">Harris, T., & Raskin, A. (Hosts). (2019, June 25). With Great Power Comes...No Responsibility? (No. 3) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                    <li><a href="http://algorithmsofoppression.com/" target="_blank">Noble, S.U. (2018). <i>Algorithms of Oppression: How Search Engines Reinforce Racism</i>. New York University Press.</a></li>
                    <li>O’Neil, C. (2016). <i>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</i>. Broadway Books.</li>
                    <li><a href="https://www.humanetech.com/the-social-dilemma" target="_blank">Orlowski, J. (Director). (2020). <i>The Social Dilemma</i> [Film]. Exposure Labs.</a></li>
                    <li><a href="https://cyber.fsi.stanford.edu/gdpi" target="_blank">Stanford Cyber Policy Center. (n.d.). Global Digital Policy Incubator [Website].</a></li>
                    <li>Zuboff, S. (2019). The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. Public Affairs Hachette Book Group.</li>
                </ul>
            </div>
        </div>
        <footer>
            <ul>
                <li><a href="index.html">HOME</a></li>
                <li><a href="resources.html">RESOURCES</a></li>
            </ul>
        </footer>
    </body>

    </html>
    </DOCTYPE>