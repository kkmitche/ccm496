<DOCTYPE! html>
    <html>

    <head>
        <title>Democracy in the Digital Age</title>
        <link href="styles.css" rel="stylesheet" type="text/css" />
    </head>

    <body>
        <header>
            <h1>OUR TECHNOLOGICAL FUTURE</h1>
            <h2>AI, BIAS & THE THREAT TO DEMOCRACY</h2>
            <nav>
                <ul>
                    <li><a href="index.html">HOME</a></li>
                    <li><a href="resources.html">RESOURCES</a></li>
                </ul>
            </nav>
        </header>
        <div class="padlet-embed" id="possDemPad" style="border:1px solid rgba(0,0,0,0.1);border-radius:2px;box-sizing:border-box;overflow:hidden;position:relative;width:100%;background:#F4F4F4">
            <p style="padding:0;margin:0"><iframe src="https://padlet.com/embed/vbb3gw3729jgkqso" scrolling="no" style="width:100%;height:500px;overflow:hidden"></iframe></p>
        </div>
        <div id="main">
            <div id="">
                <h1>Is It Possible to Have a Democracy in the Digital Age?</h1>
                <!-- <h2>....</h2> -->
                <br/>
                <p>Democracy is at the heart of the intersection between algorithms and the funding model as it lies directly within this asymmetrical power system. AI is being weaponized in ways we are only scratching the surface to understand, and without
                    transparency or regulation, we are unable to see the full extent of this existential threat posing to derail our democracy and the world as we know it.
                </p>
                <br/>
                <blockquote>"Mark Zuckerberg famously quipped that 'in a lot of ways Facebook is more like a government than a traditional company.' It is time we took this idea seriously."" - Josh Simons & Dipayan Ghosh, authors of Utilities for Democracy</blockquote>
                <br/>
                <p>Tech companies are now using Weapons Grade Mass Communication Tactics to target and manipulate users, most explicitly seen in voting outcomes. In the case of Cambridge Analytica, their company used data collected by Facebook to target
                    what they refer to as "persuadables" or people who can be persuaded to do or not do something. Looking specifically at the Do So movement, Cambridge Analytica utilized psyops - or psychological operations typically used in military
                    context - to target people they believe they could deter from voting in order to overturn a favored election in which they were successful. The fact that they succeeded in encouraging over half of the youth population to not vote,
                    thus winning the election for their candidate, is extremely unsettling and shows the power to which data can hold, especially in the hands of a select few.
                </p>
                <br/>
                <blockquote>"It’s not what will AI do to us on its own, it's what will the powerful do to us with AI?" - Coded Bias</blockquote>
                <br/>
                <p>When looking at who holds the power to manipulate us through these algorithms, it's clear that we do not have regulation in place to protect us. Power is being wielded through data collection and surveillance, so we must have a level of
                    public control over this private power. In the United States, we currently have voter suppression laws, but the Federal Election Committee has yet to find a way to enforce these on our technological platforms. These platforms should
                    also be held responsible for prohibiting misconduct in regard to political elections. Since 2019, Twitter has banned all political advertising in an effort to do just this. Facebook, on the other hand, refuses to do this because that
                    would mean admitting how dangerous and out of hand the problem really is for them. This is why we must push for government intervention, because if we don't, this asymmetry of power will continue to prevail.
                </p>
                <br/>
                <p>Digital democracy is in reach, but we need transparency and regulation in the digital sphere to get us there. One hopeful example can be seen in Taiwan, as they have a delegated digital minister who ensures transparency between the government
                    and the public, providing a great model for what digital democracy can look like. We have the capability to reach this on both a national and global scale, but we need to achieve a level of regulation and transparency to combat the
                    weaponization and manipulation we are currently facing in order to reach a true democracy in the digital age.
                </p>
                <br/>
                <br/>
                <div class="conWorks">
                    <h2>CONSULTED WORKS</h2>
                    <ul>
                        <li><a href="https://www.netflix.com/search?q=coded%20bias&jbv=80117542" target="_blank">Amer, K. & Noujaim, J. (2019). <i>The Great Hack</i> [Film]. The Othrs Media Company.</a></li>
                        <li><a href=" https://doi.org/10.1145/3342194" target="_blank">Gastil, J. & Davies, T. (2019). <i>Digital Democracy: Episode IV—A New Hope: How a Corporation for Public Software Could Transform Digital Engagement for Government and Civil Society</i>.</a></li>
                        <li><a href="https://www.humanetech.com/podcast/23-digital-democracy-is-within-reach" target="_blank">Harris, T., & Raskin, A. (Hosts). (2020, July 23). Digital Democracy is Within Reach (No. 22) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                        <li><a href="https://www.humanetech.com/podcast/10-rock-the-voter" target="_blank">Harris, T., & Raskin, A. (Hosts). (2019, December 5). Rock the Voter (No. 10) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                        <li><a href="https://www.netflix.com/title/81328723" target="_blank">Kantayya, S. (Director). (2020). <i>Coded Bias</i> [Film]. 7th Empire Media.</a></li>
                        <li><a href="https://business.twitter.com/en/help/ads-policies/ads-content-policies/political-content.html" target="_blank">Political Content. <i>Twitter</i>.</a></li>
                        <li><a href="https://www.brookings.edu/wp-content/uploads/2020/08/Simons-Ghosh_Utilities-for-Democracy_PDF.pdf" target="_blank">Simons, J. & Ghosh, D. (2020, Aug). <i>Utilities for Democracy: Why and How the Algorithmic Infrastructure of Facebook and Google Must Be Regulated</i>. Brookings Institute.</a></li>
                    </ul>
                    <br/>
                    <br/>
                </div>
            </div>

            <div class="recRes">
                <h3>RECOMMENDED RESOURCES</h3>
                <ul>
                    <li><a href="https://www.netflix.com/search?q=coded%20bias&jbv=80117542" target="_blank">Amer, K. & Noujaim, J. (2019). <i>The Great Hack</i> [Film]. The Othrs Media Company.</a></li>
                    <li><a href="https://www.humanetech.com/learn-more" target="_blank">Center for Humane Technology. (2021, Apr 5). Learn More [Website].</a></li>
                    <li><a href=" https://doi.org/10.1145/3342194" target="_blank">Gastil, J. & Davies, T. (2019). <i>Digital Democracy: Episode IV—A New Hope: How a Corporation for Public Software Could Transform Digital Engagement for Government and Civil Society</i>.</a></li>
                    <li><a href="https://www.humanetech.com/podcast/23-digital-democracy-is-within-reach" target="_blank">Harris, T., & Raskin, A. (Hosts). (2020, July 23). Digital Democracy is Within Reach (No. 22) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                    <li><a href="https://www.humanetech.com/podcast/10-rock-the-voter" target="_blank">Harris, T., & Raskin, A. (Hosts). (2019, December 5). Rock the Voter (No. 10) [Audio podcast episode]. In <i>Your Undivided Attention</i>. The Center For Humane Technology.</a></li>
                    <li><a href="https://www.netflix.com/title/81328723" target="_blank">Kantayya, S. (Director). (2020). <i>Coded Bias</i> [Film]. 7th Empire Media.</a></li>
                    <li>O’Neil, C. (2016). <i>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</i>. Broadway Books.</li>
                    <li><a href="https://www.humanetech.com/the-social-dilemma" target="_blank">Orlowski, J. (Director). (2020). <i>The Social Dilemma</i> [Film]. Exposure Labs.</a></li>
                    <li><a href="https://www.brookings.edu/wp-content/uploads/2020/08/Simons-Ghosh_Utilities-for-Democracy_PDF.pdf" target="_blank">Simons, J. & Ghosh, D. (2020, Aug). <i>Utilities for Democracy: Why and How the Algorithmic Infrastructure of Facebook and Google Must Be Regulated</i>. Brookings Institute.</a></li>
                    <li><a href="https://cyber.fsi.stanford.edu/gdp" target="_blank">Stanford Cyber Policy Center. (n.d.). Global Digital Policy Incubator [Website].</a></li>
                    <li>Zuboff, S. (2019). <i>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</i>. Public Affairs Hachette Book Group.</li>
                </ul>
            </div>
        </div>
        <footer>
            <ul>
                <li><a href="index.html">HOME</a></li>
                <li><a href="resources.html">RESOURCES</a></li>
            </ul>
        </footer>
    </body>

    </html>
    </DOCTYPE>